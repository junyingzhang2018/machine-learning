{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "\n",
    "Build a logistic regression to predict whether a student will be enrolled into a university.\n",
    "\n",
    "For the training data, we have the applicant's score on two examples and the admission decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       exam1      exam2  result\n",
      "0  34.623660  78.024693       0\n",
      "1  30.286711  43.894998       0\n",
      "        exam1      exam2  result\n",
      "98  55.340018  64.931938       1\n",
      "99  74.775893  89.529813       1\n",
      "(100, 3)\n"
     ]
    }
   ],
   "source": [
    "# Load training data, the first two columns contains the exam score and the third column contains the label\n",
    "train=pd.read_csv('ex2data1.txt', names=['exam1','exam2', 'result'])\n",
    "print(train.head(2))\n",
    "print(train.tail(2))\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X=train[['exam1','exam2']]\n",
    "y=train['result']\n",
    "m,n=X.shape[0], X.shape[1]\n",
    "X=pd.concat((pd.DataFrame(np.ones((m,1))), X), axis=1) # add x0=1 for X\n",
    "X.head(2)\n",
    "m,n=X.shape[0], X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I: Visualization: plot\n",
    "\n",
    "we start by plotting the data we are working with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.PairGrid at 0xbe03780>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAFdCAYAAAD/mTH+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTUlDRER8U9IQERHflDRERMS3/w81n+8dUR4nUQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xbe03748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.pairplot(x_vars='exam1', y_vars='exam2', data=train, hue='result',size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part II: Implementation\n",
    "\n",
    "#### 2.1 Sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-1*z))\n",
    "    \"\"\"\n",
    "    SIGMOID Compute sigmoid function\n",
    "    g = SIGMOID(z) computes the sigmoid of z.\n",
    "    Compute the sigmoid of each value of z (z can be a matrix, vector or scalar).\n",
    "    \"\"\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "[ 0.5  0.5  0.5]\n",
      "[[ 0.5  0.5  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5  0.5  0.5]]\n"
     ]
    }
   ],
   "source": [
    "# Check the sigmoid function on a scalor, series and data frame\n",
    "print(sigmoid(0))\n",
    "print(sigmoid(np.array([0,0,0])))\n",
    "print(sigmoid(np.zeros((5,5))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Cost function and gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def costFunction(theta, X, y):\n",
    "    \"\"\"\n",
    "    COSTFUNCTION Compute cost and gradient for logistic regression\n",
    "    J = COSTFUNCTION(theta, X, y) computes the cost of using theta as the parameter for logistic regression \n",
    "    and the gradient of the cost w.r.t. to the parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize some useful values\n",
    "    m = len(y)\n",
    "    grad = np.zeros(len(theta))\n",
    "\n",
    "# Compute the cost of a particular choice of theta. You should set J to the cost.\n",
    "# Compute the partial derivatives and set grad to the partial derivatives of the cost w.r.t. each parameter in theta\n",
    "    J=(-y.T.dot(np.log(sigmoid(X.dot(theta))))-(1-y).T.dot(np.log(1-sigmoid(X.dot(theta)))))/m\n",
    "    grad=X.T.dot((sigmoid(X.dot(theta))-np.array(y).reshape(m,1)))/m\n",
    "    return (J,grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.693147\n",
      "Name: result, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exam1</th>\n",
       "      <td>-12.009217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exam2</th>\n",
       "      <td>-11.262842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "0      -0.100000\n",
       "exam1 -12.009217\n",
       "exam2 -11.262842"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize fitting parameters\n",
    "initial_theta = np.zeros((n, 1))\n",
    "\n",
    "# Compute and display initial cost and gradient\n",
    "[cost, grad] = costFunction(initial_theta, X, y)\n",
    "print(cost)\n",
    "grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at initial theta (zeros): 0    0.693147\n",
      "Name: result, dtype: float64\n",
      "Expected cost (approx): 0.693\n",
      "Gradient at initial theta (zeros):                 0\n",
      "0      -0.100000\n",
      "exam1 -12.009217\n",
      "exam2 -11.262842\n",
      "Expected gradients (approx):-0.1000, -12.0092, -11.2628\n",
      "Cost at test theta: %f\n",
      " 0    0.21833\n",
      "Name: result, dtype: float64\n",
      "Expected cost (approx): 0.218\n",
      "\n",
      "Gradient at test theta: \n",
      "\n",
      " %f \n",
      "               0\n",
      "0      0.042903\n",
      "exam1  2.566234\n",
      "exam2  2.646797\n",
      "Expected gradients (approx):\n",
      " 0.043\n",
      " 2.566\n",
      " 2.647\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Cost at initial theta (zeros):', cost)\n",
    "print('Expected cost (approx): 0.693')\n",
    "print('Gradient at initial theta (zeros): ', grad);\n",
    "print('Expected gradients (approx):-0.1000, -12.0092, -11.2628')\n",
    "\n",
    "# Compute and display cost and gradient with non-zero theta\n",
    "test_theta = np.array([-24, 0.2, 0.2]).reshape(3,1)\n",
    "[cost, grad] = costFunction(test_theta, X, y)\n",
    "\n",
    "print('Cost at test theta: %f\\n', cost)\n",
    "print('Expected cost (approx): 0.218\\n')\n",
    "print('Gradient at test theta: \\n')\n",
    "print(' %f \\n', grad)\n",
    "print('Expected gradients (approx):\\n 0.043\\n 2.566\\n 2.647\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Learning parameters using fminunc\n",
    "\n",
    "Concretely, you are going to use fminunc to find the best parameters theta\n",
    "for the logistic regression cost function, given a fixed dataset (of X and y\n",
    "values). You will pass to fminunc the following inputs:\n",
    "\n",
    "1. The initial values of the parameters we are trying to optimize theta\n",
    "\n",
    "2. A function, given the training set (X,y) that compute the J, grad with respect to theta data (X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 77.74468294, -25.66384708,  -4.04583556])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.optimize as op\n",
    "\n",
    "def Sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z));\n",
    "\n",
    "def Gradient(theta,x,y):\n",
    "    m , n = x.shape\n",
    "    theta = theta.reshape((n,1));\n",
    "    y = y.reshape((m,1))\n",
    "    sigmoid_x_theta = Sigmoid(x.dot(theta));\n",
    "    grad = ((x.T).dot(sigmoid_x_theta-y))/m;\n",
    "    return grad.flatten();\n",
    "\n",
    "def CostFunc(theta,x,y):\n",
    "    m,n = x.shape; \n",
    "    theta = theta.reshape((n,1));\n",
    "    y = y.reshape((m,1));\n",
    "    term1 = np.log(Sigmoid(x.dot(theta)));\n",
    "    term2 = np.log(1-Sigmoid(x.dot(theta)));\n",
    "    term1 = term1.reshape((m,1))\n",
    "    term2 = term2.reshape((m,1))\n",
    "    term = y * term1 + (1 - y) * term2;  #element multiplication, not matrix multiplication\n",
    "    J = -((np.sum(term))/m);\n",
    "    return J;\n",
    "\n",
    "# intialize X and y\n",
    "X = np.array([[1,2,3],[1,3,4]]);\n",
    "y = np.array([[1],[0]]);\n",
    "\n",
    "m , n = X.shape;\n",
    "initial_theta = np.zeros(n);\n",
    "Result = op.minimize(fun = CostFunc, x0 = initial_theta, args = (X, y),method = 'TNC',jac = Gradient);\n",
    "optimal_theta = Result.x;     \n",
    "optimal_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 77.74468294, -25.66384708,  -4.04583556])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.optimize as op\n",
    "\n",
    "def Sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z));\n",
    "\n",
    "def Gradient(theta,x,y):\n",
    "    m , n = x.shape\n",
    "    theta = theta.reshape((n,1));\n",
    "    y = y.reshape((m,1))\n",
    "    sigmoid_x_theta = Sigmoid(x.dot(theta));\n",
    "    grad = ((x.T).dot(sigmoid_x_theta-y))/m;\n",
    "    return grad.flatten();\n",
    "\n",
    "def CostFunc(theta,x,y):\n",
    "    m,n = x.shape; \n",
    "    theta = theta.reshape((n,1));\n",
    "    y = y.reshape((m,1));\n",
    "    term1 = np.log(Sigmoid(x.dot(theta)));\n",
    "    term2 = np.log(1-Sigmoid(x.dot(theta)));\n",
    "    term1 = term1.reshape((m,1))\n",
    "    term2 = term2.reshape((m,1))\n",
    "    term = y * term1 + (1 - y) * term2;\n",
    "    J = -((np.sum(term))/m);\n",
    "    return J;\n",
    "\n",
    "# intialize X and y\n",
    "X = np.array([[1,2,3],[1,3,4]]);\n",
    "y = np.array([[1],[0]]);\n",
    "\n",
    "m , n = X.shape;\n",
    "initial_theta = np.zeros(n);\n",
    "Result = op.minimize(fun = CostFunc, x0 = initial_theta, args = (X, y),method = 'TNC',jac = Gradient);\n",
    "optimal_theta = Result.x;     \n",
    "optimal_theta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
